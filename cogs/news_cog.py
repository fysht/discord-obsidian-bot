import os
import discord
from discord import app_commands
from discord.ext import commands, tasks
import logging
import json
from datetime import datetime, time
import zoneinfo
import dropbox
from dropbox.files import WriteMode, DownloadError
from dropbox.exceptions import ApiError
import asyncio
from pyowm import OWM
import google.generativeai as genai

# ä»–ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰é–¢æ•°ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from web_parser import parse_url_with_readability

# --- å®šæ•°å®šç¾© ---
JST = zoneinfo.ZoneInfo("Asia/Tokyo")
NEWS_BRIEFING_TIME = time(hour=1, minute=10, tzinfo=JST)

class NewsCog(commands.Cog):
    """å¤©æ°—äºˆå ±ã¨æ ªå¼é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å®šæ™‚é€šçŸ¥ã™ã‚‹Cog"""

    def __init__(self, bot: commands.Bot):
        self.bot = bot
        self.is_ready = False
        self._load_environment_variables()
        
        if not self._are_credentials_valid():
            logging.error("NewsCog: å¿…é ˆã®ç’°å¢ƒå¤‰æ•°ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚ã“ã®Cogã¯ç„¡åŠ¹åŒ–ã•ã‚Œã¾ã™ã€‚")
            return
            
        try:
            self.dbx = dropbox.Dropbox(
                oauth2_refresh_token=self.dropbox_refresh_token,
                app_key=self.dropbox_app_key,
                app_secret=self.dropbox_app_secret
            )
            self.owm = OWM(self.openweathermap_api_key)
            self.mgr = self.owm.weather_manager()
            
            if self.gemini_api_key:
                genai.configure(api_key=self.gemini_api_key)
                self.gemini_model = genai.GenerativeModel("gemini-2.5-pro")
            else:
                self.gemini_model = None
                logging.warning("NewsCog: GEMINI_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ãªã„ãŸã‚ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹è¦ç´„æ©Ÿèƒ½ã¯ç„¡åŠ¹ã§ã™ã€‚")

            self.is_ready = True
            logging.info("âœ… NewsCogãŒæ­£å¸¸ã«åˆæœŸåŒ–ã•ã‚Œã¾ã—ãŸã€‚")
        except Exception as e:
            logging.error(f"âŒ NewsCogã®åˆæœŸåŒ–ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}", exc_info=True)

    def _load_environment_variables(self):
        self.news_channel_id = int(os.getenv("NEWS_CHANNEL_ID", 0))
        self.home_coords = self._parse_coordinates(os.getenv("HOME_COORDINATES"))
        self.work_coords = self._parse_coordinates(os.getenv("WORK_COORDINATES"))
        self.home_name = os.getenv("HOME_NAME", "è‡ªå®…")
        self.work_name = os.getenv("WORK_NAME", "å‹¤å‹™å…ˆ")
        self.openweathermap_api_key = os.getenv("OPENWEATHERMAP_API_KEY")
        self.dropbox_app_key = os.getenv("DROPBOX_APP_KEY")
        self.dropbox_app_secret = os.getenv("DROPBOX_APP_SECRET")
        self.dropbox_refresh_token = os.getenv("DROPBOX_REFRESH_TOKEN")
        self.dropbox_vault_path = os.getenv("DROPBOX_VAULT_PATH", "/ObsidianVault")
        self.gemini_api_key = os.getenv("GEMINI_API_KEY")
        self.watchlist_path = f"{self.dropbox_vault_path}/.bot/stock_watchlist.json"

    def _are_credentials_valid(self) -> bool:
        return all([self.news_channel_id, self.home_coords, self.work_coords, self.openweathermap_api_key, self.dropbox_app_key, self.dropbox_app_secret, self.dropbox_refresh_token, self.gemini_api_key])

    def _parse_coordinates(self, coord_str: str | None) -> dict | None:
        if not coord_str: return None
        try:
            lat, lon = map(float, coord_str.split(','))
            return {'lat': lat, 'lon': lon}
        except (ValueError, TypeError):
            logging.error(f"åº§æ¨™ã®è§£æã«å¤±æ•—: {coord_str}")
            return None

    @commands.Cog.listener()
    async def on_ready(self):
        if self.is_ready and not self.daily_news_briefing.is_running():
            self.daily_news_briefing.start()

    def cog_unload(self):
        self.daily_news_briefing.cancel()
        
    async def _get_weather_forecast(self, coords: dict, location_name: str) -> str:
        try:
            one_call = await asyncio.to_thread(self.mgr.one_call, lat=coords['lat'], lon=coords['lon'], exclude='current,minutely,hourly', units='metric')
            daily_weather = one_call.forecast_daily[0]
            temp = daily_weather.temperature('celsius')
            pop = daily_weather.precipitation_probability * 100
            return f"**{location_name}**: {daily_weather.detailed_status} | æœ€é«˜ {temp['max']:.0f}â„ƒ / æœ€ä½ {temp['min']:.0f}â„ƒ | é™æ°´ç¢ºç‡ {pop:.0f}%"
        except Exception as e:
            logging.error(f"{location_name}ã®å¤©æ°—äºˆå ±å–å¾—ã«å¤±æ•—: {e}")
            return f"**{location_name}**: å¤©æ°—æƒ…å ±ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚"

    async def _summarize_article(self, content: str) -> str:
        if not self.gemini_model or not content:
            return "è¦ç´„ã®ç”Ÿæˆã«å¤±æ•—ã—ãŸã€‚"
        try:
            prompt = f"ä»¥ä¸‹ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã‚’3ï½4æ–‡ç¨‹åº¦ã®ç°¡æ½”ãªã€Œã ã§ã‚ã‚‹èª¿ã€ã§è¦ç´„ã›ã‚ˆã€‚\n---{content[:8000]}"
            response = await self.gemini_model.generate_content_async(prompt)
            return response.text.strip()
        except Exception as e:
            logging.error(f"ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®è¦ç´„ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            return "è¦ç´„ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸã€‚"

    async def _search_and_summarize_news(self, queries: list, max_articles: int = 1) -> list:
        news_items = []
        try:
            logging.info(f"Googleæ¤œç´¢ã‚’é–‹å§‹ã—ã¾ã™ã€‚ã‚¯ã‚¨ãƒª: {queries}")
            search_results = await self.bot.google_search(queries=queries)
            logging.info(f"Googleæ¤œç´¢ãŒå®Œäº†ã—ã¾ã—ãŸã€‚{len(search_results)}ä»¶ã®çµæœãƒªã‚¹ãƒˆã‚’å–å¾—ã—ã¾ã—ãŸã€‚")
            
            seen_urls = set()
            urls_to_process = []
            
            for result_list in search_results:
                if not result_list.results:
                    continue
                for item in result_list.results:
                    if item.url not in seen_urls:
                        urls_to_process.append(item)
                        seen_urls.add(item.url)
                    if len(urls_to_process) >= max_articles * len(queries): # Ensure we don't process too many
                        break
                if len(urls_to_process) >= max_articles * len(queries):
                    break
            
            urls_to_process = urls_to_process[:max_articles]

            logging.info(f"è¦ç´„å¯¾è±¡ã®è¨˜äº‹ã¯ {len(urls_to_process)} ä»¶ã§ã™ã€‚")
            for item in urls_to_process:
                _, content = await asyncio.to_thread(parse_url_with_readability, item.url)
                summary = await self._summarize_article(content)
                news_items.append({"title": item.source_title, "link": item.url, "summary": summary})

            return news_items
        except Exception as e:
            logging.error(f"ãƒ‹ãƒ¥ãƒ¼ã‚¹å‡¦ç†ä¸­ã«å¤±æ•—: {queries}, {e}", exc_info=True)
            return []

    @tasks.loop(time=NEWS_BRIEFING_TIME)
    async def daily_news_briefing(self):
        channel = self.bot.get_channel(self.news_channel_id)
        if not channel:
            logging.error(f"ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒãƒ£ãƒ³ãƒãƒ«(ID: {self.news_channel_id})ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            return
            
        logging.info("ãƒ‡ã‚¤ãƒªãƒ¼ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ–ãƒªãƒ¼ãƒ•ã‚£ãƒ³ã‚°ã‚’é–‹å§‹ã—ã¾ã™...")
        
        # --- å¤©æ°—äºˆå ±ã‚’æŠ•ç¨¿ ---
        home_weather, work_weather = await asyncio.gather(
            self._get_weather_forecast(self.home_coords, self.home_name),
            self._get_weather_forecast(self.work_coords, self.work_name)
        )
        weather_embed = discord.Embed(
            title=f"ğŸ—“ï¸ {datetime.now(JST).strftime('%Yå¹´%mæœˆ%dæ—¥')} ã®ãŠçŸ¥ã‚‰ã›",
            color=discord.Color.blue()
        )
        weather_embed.add_field(name="ğŸŒ¦ï¸ ä»Šæ—¥ã®å¤©æ°—", value=f"{home_weather}\n{work_weather}", inline=False)
        await channel.send(embed=weather_embed)

        # --- ãƒã‚¯ãƒ­çµŒæ¸ˆãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’æŠ•ç¨¿ ---
        target_sites = [
            "site:nikkei.com", "site:toyokeizai.net", "site:weekly-economist.mainichi.jp",
            "site:jp.reuters.com", "site:bloomberg.co.jp", "site:pwc.com", "site:murc.jp"
        ]
        sites_query = " OR ".join(target_sites)
        
        market_queries = [f"({sites_query}) çµŒæ¸ˆ"]
        
        market_news = await self._search_and_summarize_news(market_queries, max_articles=3)
        if market_news:
            macro_embed = discord.Embed(title="ğŸŒ å¸‚å ´å…¨ä½“ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹", color=discord.Color.dark_gold())
            news_text = ""
            for item in market_news:
                summary = item['summary'][:250] + "..." if len(item['summary']) > 250 else item['summary']
                news_text += f"**[{item['title']}]({item['link']})**\n```{summary}```\n"
            macro_embed.description = news_text
            await channel.send(embed=macro_embed)
        else:
            logging.info("ãƒã‚¯ãƒ­çµŒæ¸ˆãƒ‹ãƒ¥ãƒ¼ã‚¹ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

        # --- ä¿æœ‰éŠ˜æŸ„ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’æŠ•ç¨¿ ---
        watchlist = await self._get_watchlist()
        if watchlist:
            logging.info(f"{len(watchlist)}ä»¶ã®ä¿æœ‰éŠ˜æŸ„ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¾ã™ã€‚")
            for company in watchlist:
                # æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’å…¬å¼ç™ºè¡¨ï¼ˆæ±ºç®—ã€é©æ™‚é–‹ç¤ºã€IRï¼‰ã«çµã‚Šè¾¼ã‚€
                company_queries = [f"{company} (æ±ºç®— OR é©æ™‚é–‹ç¤º OR IR)"]
                company_news = await self._search_and_summarize_news(company_queries, max_articles=1)
                
                if company_news:
                    item = company_news[0]
                    stock_embed = discord.Embed(title=f"ğŸ“ˆ ä¿æœ‰éŠ˜æŸ„ãƒ‹ãƒ¥ãƒ¼ã‚¹: {company}", color=discord.Color.green())
                    summary = item['summary'][:200] + "..." if len(item['summary']) > 200 else item['summary']
                    stock_embed.description = f"**[{item['title']}]({item['link']})**\n```{summary}```\n"
                    await channel.send(embed=stock_embed)
                
                await asyncio.sleep(2) # é€£ç¶šãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é¿ã‘ã‚‹ãŸã‚ã®å¾…æ©Ÿ
        
        logging.info("ãƒ‡ã‚¤ãƒªãƒ¼ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ–ãƒªãƒ¼ãƒ•ã‚£ãƒ³ã‚°ã‚’é€ä¿¡ã—ã¾ã—ãŸã€‚")
        
    async def _get_watchlist(self) -> list:
        try:
            _, res = self.dbx.files_download(self.watchlist_path)
            return json.loads(res.content)
        except ApiError:
            return []

    async def _save_watchlist(self, watchlist: list):
        try:
            self.dbx.files_upload(json.dumps(watchlist, ensure_ascii=False, indent=2).encode('utf-8'),
                                  self.watchlist_path, mode=WriteMode('overwrite'))
        except Exception as e:
            logging.error(f"ã‚¦ã‚©ãƒƒãƒãƒªã‚¹ãƒˆã®ä¿å­˜ã«å¤±æ•—: {e}")

    stock_group = app_commands.Group(name="stock", description="æ ªä¾¡ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®ç›£è¦–ãƒªã‚¹ãƒˆã‚’ç®¡ç†ã—ã¾ã™ã€‚")

    @stock_group.command(name="add", description="ç›£è¦–ãƒªã‚¹ãƒˆã«æ–°ã—ã„ä¼æ¥­ã‚’è¿½åŠ ã—ã¾ã™ã€‚")
    @app_commands.describe(company="è¿½åŠ ã™ã‚‹ä¼æ¥­åã¾ãŸã¯éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰")
    async def stock_add(self, interaction: discord.Interaction, company: str):
        watchlist = await self._get_watchlist()
        if company not in