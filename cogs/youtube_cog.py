import os
import discord
from discord import app_commands
from discord.ext import commands
import logging
import re
import asyncio
import dropbox
from dropbox.files import WriteMode, DownloadError
from dropbox.exceptions import ApiError
import datetime
import zoneinfo
import aiohttp
import google.generativeai as genai
from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled, NoTranscriptFound

# --- å…±é€šé–¢æ•°ã‚¤ãƒ³ãƒãƒ¼ãƒˆ ---
try:
    from utils.obsidian_utils import update_section
    logging.info("YouTubeCog: utils/obsidian_utils.py ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")
except ImportError:
    logging.warning("YouTubeCog: utils/obsidian_utils.pyãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€ç°¡æ˜“çš„ãªè¿½è¨˜å‡¦ç†ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
    def update_section(current_content: str, text_to_add: str, section_header: str) -> str:
        lines = current_content.split('\n')
        new_content_lines = list(lines)
        try:
            heading_index = -1
            for i, line in enumerate(new_content_lines):
                if line.strip().lstrip('#').strip() == section_header.lstrip('#').strip():
                    heading_index = i
                    break
            if heading_index == -1: raise ValueError("Header not found")
            insert_index = heading_index + 1
            while insert_index < len(new_content_lines) and not new_content_lines[insert_index].strip().startswith('## '):
                insert_index += 1
            if insert_index > heading_index + 1 and new_content_lines[insert_index - 1].strip() != "":
                new_content_lines.insert(insert_index, "")
                insert_index += 1
            new_content_lines.insert(insert_index, text_to_add)
            # â˜… ä¿®æ­£: join(lines) ã ã£ãŸã‚‚ã®ã‚’ join(new_content_lines) ã«
            return "\n".join(new_content_lines) 
        except ValueError:
            logging.info(f"Section '{section_header}' not found in daily note, appending.")
            return current_content.strip() + f"\n\n{section_header}\n{text_to_add}\n"
# --- ã“ã“ã¾ã§ ---

# --- â˜… æ–°è¦è¿½åŠ : Webãƒ‘ãƒ¼ã‚µãƒ¼ã‚¤ãƒ³ãƒãƒ¼ãƒˆ ---
try:
    from web_parser import parse_url_with_readability
    logging.info("YouTubeCog: web_parser ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ (ãƒ¬ã‚·ãƒ”æ©Ÿèƒ½ç”¨)ã€‚")
except ImportError:
    logging.warning("YouTubeCog: web_parser ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚Webãƒ¬ã‚·ãƒ”ã®è§£æã¯ç„¡åŠ¹ã§ã™ã€‚")
    parse_url_with_readability = None
# --- â˜… æ–°è¦è¿½åŠ ã“ã“ã¾ã§ ---

# --- Google Docsé€£æº ---
try:
    from google_docs_handler import append_text_to_doc_async
    google_docs_enabled = True
    logging.info("YouTubeCog: Google Docsé€£æºãŒæœ‰åŠ¹ã§ã™ã€‚")
except ImportError:
    logging.warning("YouTubeCog: google_docs_handler.pyãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€Google Docsé€£æºã¯ç„¡åŠ¹ã§ã™ã€‚")
    google_docs_enabled = False
    async def append_text_to_doc_async(*args, **kwargs):
        logging.warning("Google Docs handler is not available.")
        pass
# --- ã“ã“ã¾ã§ ---

# --- å®šæ•°å®šç¾© ---
JST = zoneinfo.ZoneInfo("Asia/Tokyo")
YOUTUBE_URL_REGEX = re.compile(r'https?://(?:www\.)?(?:youtube\.com/watch\?v=|youtu\.be/|youtube\.com/embed/|youtube\.com/shorts/)([a-zA-Z0-9_-]{11})')
BOT_PROCESS_TRIGGER_REACTION = 'ğŸ“¥' 
PROCESS_START_EMOJI = 'â³'
PROCESS_COMPLETE_EMOJI = 'âœ…'
PROCESS_ERROR_EMOJI = 'âŒ'
TRANSCRIPT_NOT_FOUND_EMOJI = 'ğŸ”‡' # (Webè§£æå¤±æ•—ã«ã‚‚æµç”¨)
INVALID_URL_EMOJI = 'â“'
SUMMARY_ERROR_EMOJI = 'âš ï¸'
SAVE_ERROR_EMOJI = 'ğŸ’¾'
GOOGLE_DOCS_ERROR_EMOJI = 'ğŸ‡¬'
# --- ã“ã“ã¾ã§ ---

class YouTubeCog(commands.Cog, name="YouTubeCog"): # name ã‚’æŒ‡å®š
    """YouTubeå‹•ç”»ã¨Webãƒ¬ã‚·ãƒ”ã®è¦ç´„ãƒ»ä¿å­˜ã‚’è¡Œã†Cog (Botãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒˆãƒªã‚¬ãƒ¼)"""

    def __init__(self, bot: commands.Bot):
        self.bot = bot
        self.youtube_summary_channel_id = int(os.getenv("YOUTUBE_SUMMARY_CHANNEL_ID", 0))
        # â˜… ä¿®æ­£: ãƒ¬ã‚·ãƒ”ãƒãƒ£ãƒ³ãƒãƒ«IDã‚’èª­ã¿è¾¼ã‚€
        self.recipe_channel_id = int(os.getenv("RECIPE_CHANNEL_ID", 0)) 
        self.dropbox_app_key = os.getenv("DROPBOX_APP_KEY")
        self.dropbox_app_secret = os.getenv("DROPBOX_APP_SECRET")
        self.dropbox_refresh_token = os.getenv("DROPBOX_REFRESH_TOKEN")
        self.dropbox_vault_path = os.getenv("DROPBOX_VAULT_PATH", "/ObsidianVault")
        self.gemini_api_key = os.getenv("GEMINI_API_KEY")
        
        self.dbx = None
        self.gemini_model = None
        self.session = None
        self.is_ready = False

        missing_vars = []
        # â˜… ä¿®æ­£: ãƒãƒ£ãƒ³ãƒãƒ«IDã®ãƒã‚§ãƒƒã‚¯
        if not self.youtube_summary_channel_id and not self.recipe_channel_id: 
            missing_vars.append("YOUTUBE_SUMMARY_CHANNEL_ID or RECIPE_CHANNEL_ID")
        if not self.dropbox_app_key: missing_vars.append("DROPBOX_APP_KEY")
        if not self.dropbox_app_secret: missing_vars.append("DROPBOX_APP_SECRET")
        if not self.dropbox_refresh_token: missing_vars.append("DROPBOX_REFRESH_TOKEN")
        if not self.gemini_api_key: missing_vars.append("GEMINI_API_KEY")
        # â˜… ä¿®æ­£: Webãƒ¬ã‚·ãƒ”æ©Ÿèƒ½ã®ãŸã‚ã« web_parser ã®å­˜åœ¨ã‚‚ãƒã‚§ãƒƒã‚¯
        if self.recipe_channel_id and not parse_url_with_readability:
            logging.warning("YouTubeCog: RECIPE_CHANNEL_IDãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã™ãŒã€web_parserãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            # å¿…é ˆã‚¨ãƒ©ãƒ¼ã«ã¯ã—ãªã„

        if missing_vars:
            logging.error(f"YouTubeCog: å¿…è¦ãªç’°å¢ƒå¤‰æ•° ({', '.join(missing_vars)}) ãŒä¸è¶³ã€‚Cogã¯å‹•ä½œã—ã¾ã›ã‚“ã€‚")
            return

        try:
            self.dbx = dropbox.Dropbox(
                oauth2_refresh_token=self.dropbox_refresh_token,
                app_key=self.dropbox_app_key, app_secret=self.dropbox_app_secret, timeout=300
            )
            self.dbx.users_get_current_account()
            logging.info("YouTubeCog: Dropbox client initialized.")

            genai.configure(api_key=self.gemini_api_key)
            self.gemini_model = genai.GenerativeModel("gemini-2.5-pro")
            logging.info("YouTubeCog: Gemini client initialized.")

            self.session = aiohttp.ClientSession()
            logging.info("YouTubeCog: aiohttp session started.")

            self.is_ready = True
        except Exception as e:
            logging.error(f"YouTubeCog: Failed to initialize clients: {e}", exc_info=True)


    async def cog_unload(self):
        if self.session and not self.session.closed:
            await self.session.close()
            logging.info("YouTubeCog: aiohttp session closed.")

    # --- â˜… ä¿®æ­£: on_raw_reaction_add (ãƒ¬ã‚·ãƒ”ãƒãƒ£ãƒ³ãƒãƒ«ã‚‚ç›£è¦–å¯¾è±¡ã«) ---
    @commands.Cog.listener()
    async def on_raw_reaction_add(self, payload: discord.RawReactionActionEvent):
        """
        Bot(Render/è‡ªåˆ†è‡ªèº«)ãŒä»˜ã‘ãŸ ğŸ“¥ ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ¤œçŸ¥ã—ã¦å‡¦ç†ã‚’é–‹å§‹ã™ã‚‹
        """
        
        # â˜… ä¿®æ­£: youtube_summary_channel_id ã¨ recipe_channel_id ã®ä¸¡æ–¹ã‚’ç›£è¦–
        if payload.channel_id not in (self.youtube_summary_channel_id, self.recipe_channel_id):
            return
            
        emoji_str = str(payload.emoji)

        # 1. ã“ã®ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã¯ãƒˆãƒªã‚¬ãƒ¼(ğŸ“¥)ã‹ï¼Ÿ
        if emoji_str == BOT_PROCESS_TRIGGER_REACTION: # 'ğŸ“¥'
            
            # 2. ã“ã®ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã¯ Bot (ï¼è‡ªåˆ†è‡ªèº«) ãŒä»˜ã‘ãŸã‚‚ã®ã‹ï¼Ÿ
            if payload.user_id != self.bot.user.id:
                # é•ã†å ´åˆ (äººé–“ã‚„ä»–ã®BotãŒ ğŸ“¥ ã‚’ä»˜ã‘ãŸå ´åˆ) ã¯ç„¡è¦–
                return 

            # 3. ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å–å¾—
            channel = self.bot.get_channel(payload.channel_id)
            if not channel: return
            try:
                message = await channel.fetch_message(payload.message_id)
            except (discord.NotFound, discord.Forbidden):
                logging.warning(f"ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {payload.message_id}")
                return

            # 4. æ—¢ã« local_worker (r.me) ãŒå‡¦ç†ä¸­/å‡¦ç†å®Œäº†ã®ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä»˜ã‘ã¦ã„ã‚‹ã‹ï¼Ÿ
            is_processed = any(r.emoji in (
                PROCESS_START_EMOJI, PROCESS_COMPLETE_EMOJI, PROCESS_ERROR_EMOJI, 
                TRANSCRIPT_NOT_FOUND_EMOJI, INVALID_URL_EMOJI, SUMMARY_ERROR_EMOJI,
                SAVE_ERROR_EMOJI, GOOGLE_DOCS_ERROR_EMOJI
                ) and r.me for r in message.reactions)
            
            if is_processed:
                logging.info(f"æ—¢ã«å‡¦ç†ä¸­ã¾ãŸã¯å‡¦ç†æ¸ˆã¿ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™: {message.jump_url}")
                return

            # 5. ã€å‡¦ç†å®Ÿè¡Œã€‘
            logging.info(f"Bot (self) ã® '{BOT_PROCESS_TRIGGER_REACTION}' ã‚’æ¤œçŸ¥ã—ã¾ã—ãŸã€‚å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™: {message.jump_url}")
            
            # ãƒˆãƒªã‚¬ãƒ¼ ğŸ“¥ (Bot/è‡ªåˆ† ãŒä»˜ã‘ãŸã‚‚ã®) ã‚’å‰Šé™¤
            try:
                await message.remove_reaction(payload.emoji, self.bot.user)
            except discord.HTTPException:
                logging.warning(f"Bot ã®ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³å‰Šé™¤ã«å¤±æ•—ã—ã¾ã—ãŸ: {message.jump_url}")

            await self._perform_summary(url=message.content.strip(), message=message)

        # 6. ã“ã®ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãŒãƒˆãƒªã‚¬ãƒ¼(ğŸ“¥)ä»¥å¤–ã§ã€ã‹ã¤è‡ªåˆ†è‡ªèº«ãŒä»˜ã‘ãŸã‚‚ã® (â³, âœ…, âŒ ãªã©)
        elif payload.user_id == self.bot.user.id:
            # è‡ªåˆ†ãŒä»˜ã‘ãŸå‡¦ç†ä¸­ãƒ»å®Œäº†ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ¤œçŸ¥ã—ã¦ã‚‚ä½•ã‚‚ã—ãªã„ (ãƒ«ãƒ¼ãƒ—é˜²æ­¢)
            return
            
        # 7. ãã‚Œä»¥å¤– (äººé–“ãŒä»˜ã‘ãŸãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãªã©)
        else:
            # ç„¡è¦–
            return
    # --- ä¿®æ­£ã“ã“ã¾ã§ ---


    # --- å­—å¹•æŠ½å‡ºãƒ­ã‚¸ãƒƒã‚¯ (å¤‰æ›´ãªã—) ---
    def _extract_transcript_text(self, fetched_data):
        texts = []
        try:
            for snippet in fetched_data:
                if isinstance(snippet, dict):
                    texts.append(snippet.get('text', ''))
                elif hasattr(snippet, 'text'):
                    texts.append(getattr(snippet, 'text', ''))
                else:
                    texts.append(str(snippet))
            return " ".join(t.strip() for t in texts if t and t.strip())
        except TypeError:
            if isinstance(fetched_data, list):
                for item in fetched_data:
                        if isinstance(item, dict):
                            texts.append(item.get('text', ''))
                return " ".join(t.strip() for t in texts if t and t.strip())
            
            logging.warning(f"äºˆæœŸã›ã¬å­—å¹•ãƒ‡ãƒ¼ã‚¿å½¢å¼ã®ãŸã‚ã€ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸ: {type(fetched_data)}")
            return ""
    # --- ã“ã“ã¾ã§ ---

    # --- èµ·å‹•æ™‚ã‚¹ã‚­ãƒ£ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ (â˜… ä¿®æ­£: ãƒ¬ã‚·ãƒ”ãƒãƒ£ãƒ³ãƒãƒ«ã‚‚ã‚¹ã‚­ãƒ£ãƒ³å¯¾è±¡ã«) ---
    async def process_pending_summaries(self):
        """èµ·å‹•æ™‚ãªã©ã«æœªå‡¦ç†ã®è¦ç´„ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ã¾ã¨ã‚ã¦å‡¦ç†ã™ã‚‹é–¢æ•°"""
        
        # â˜… ä¿®æ­£: ç›£è¦–å¯¾è±¡ãƒãƒ£ãƒ³ãƒãƒ«ã‚’ãƒªã‚¹ãƒˆåŒ–
        scan_channels = []
        if self.youtube_summary_channel_id:
            scan_channels.append(self.bot.get_channel(self.youtube_summary_channel_id))
        if self.recipe_channel_id:
            # IDãŒåŒã˜å ´åˆã¯é‡è¤‡ã•ã›ãªã„
            if self.recipe_channel_id != self.youtube_summary_channel_id:
                scan_channels.append(self.bot.get_channel(self.recipe_channel_id))

        if not scan_channels:
            logging.error("YouTubeCog: ã‚¹ã‚­ãƒ£ãƒ³å¯¾è±¡ã®ãƒãƒ£ãƒ³ãƒãƒ« (YouTube/Recipe) ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            return
            
        pending_messages = []
        
        for channel in scan_channels:
            if not channel:
                logging.warning(f"YouTubeCog: ãƒãƒ£ãƒ³ãƒãƒ«ID (YouTube or Recipe) ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
                continue

            logging.info(f"ãƒãƒ£ãƒ³ãƒãƒ« '{channel.name}' ã®æœªå‡¦ç†ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’ã‚¹ã‚­ãƒ£ãƒ³ã—ã¾ã™...")
            
            try:
                async for message in channel.history(limit=200):
                    
                    has_pending_trigger_by_bot = False # ğŸ“¥ (BotãŒä»˜ã‘ãŸ)
                    is_processed_by_local = False # âœ…, âŒ, ğŸ”‡... (by local)
                    is_stuck_processing_local = False # â³ (by local)

                    for r in message.reactions:
                        emoji_str = str(r.emoji)

                        if emoji_str == BOT_PROCESS_TRIGGER_REACTION: # ğŸ“¥
                            if r.me: 
                                has_pending_trigger_by_bot = True
                        
                        if emoji_str in (
                            PROCESS_COMPLETE_EMOJI, PROCESS_ERROR_EMOJI, TRANSCRIPT_NOT_FOUND_EMOJI, 
                            INVALID_URL_EMOJI, SUMMARY_ERROR_EMOJI, SAVE_ERROR_EMOJI, GOOGLE_DOCS_ERROR_EMOJI
                        ) and r.me:
                            is_processed_by_local = True
                        
                        if emoji_str == PROCESS_START_EMOJI and r.me: # â³
                            is_stuck_processing_local = True 
                            logging.info(f"Message {message.id} (Ch: {channel.name}): â³ (Stuck) ã‚’æ¤œçŸ¥ã€‚")


                    if (has_pending_trigger_by_bot or is_stuck_processing_local) and not is_processed_by_local:
                        logging.info(f"Message {message.id} (Ch: {channel.name}): å‡¦ç†å¯¾è±¡ã«è¿½åŠ ã—ã¾ã™ã€‚")
                        pending_messages.append(message) # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã ã‘è¿½åŠ 
                
            except discord.Forbidden:
                logging.error(f"ãƒãƒ£ãƒ³ãƒãƒ« {channel.name} ã®å±¥æ­´èª­ã¿å–ã‚Šæ¨©é™ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
                continue
            except discord.HTTPException as e:
                logging.error(f"ãƒãƒ£ãƒ³ãƒãƒ« {channel.name} ã®å±¥æ­´èª­ã¿å–ã‚Šä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
                continue
        # --- ãƒ«ãƒ¼ãƒ—ã“ã“ã¾ã§ ---

        if not pending_messages:
            logging.info("å‡¦ç†å¯¾è±¡ã®æ–°ã—ã„YouTube/Recipeè¦ç´„ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            return

        logging.info(f"{len(pending_messages)}ä»¶ã®æœªå‡¦ç†YouTube/Recipeè¦ç´„ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚å¤ã„ã‚‚ã®ã‹ã‚‰é †ã«å‡¦ç†ã—ã¾ã™...")
        
        # â˜… ä¿®æ­£: created_atã§ã‚½ãƒ¼ãƒˆ
        pending_messages.sort(key=lambda m: m.created_at)

        for message in pending_messages:
            logging.info(f"å‡¦ç†é–‹å§‹: {message.jump_url}")
            url = message.content.strip()
            
            try:
                # ğŸ“¥ ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’ã‚¯ãƒªã‚¢
                await message.clear_reaction(BOT_PROCESS_TRIGGER_REACTION)
            except (discord.Forbidden, discord.NotFound, discord.HTTPException) as e:
                logging.warning(f"ğŸ“¥ ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ã‚¯ãƒªã‚¢ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            
            try:
                # â³ ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚‚ã‚¯ãƒªã‚¢ (ã‚¹ã‚¿ãƒƒã‚¯å¯¾å¿œ)
                await message.clear_reaction(PROCESS_START_EMOJI)
            except (discord.Forbidden, discord.NotFound, discord.HTTPException):
                pass 
            
            await self._perform_summary(url=url, message=message)
            await asyncio.sleep(5) # é€£ç¶šå‡¦ç†ã®ãŸã‚ã®å¾…æ©Ÿ
    # --- èµ·å‹•æ™‚ã‚¹ã‚­ãƒ£ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ä¿®æ­£ã“ã“ã¾ã§ ---


    # --- â˜… ä¿®æ­£: _perform_summary (Webãƒ¬ã‚·ãƒ”å¯¾å¿œ) ---
    async def _perform_summary(self, url: str, message: discord.Message | discord.InteractionMessage):
        """YouTubeè¦ç´„ã¾ãŸã¯Webãƒ¬ã‚·ãƒ”æŠ½å‡ºå‡¦ç†ã®ã‚³ã‚¢ãƒ­ã‚¸ãƒƒã‚¯"""
        obsidian_save_success = False
        gdoc_save_success = False
        error_reactions = set()
        video_title = "Untitled" # â˜… ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆåã‚’å¤‰æ›´
        video_id = None
        transcript_text = ""
        title_from_content = None # â˜… Webãƒšãƒ¼ã‚¸ã‚¿ã‚¤ãƒˆãƒ«ç”¨

        # â˜… ä¿®æ­£: is_recipe_channel ã®åˆ¤å®šã‚’ message.channel.id ã§è¡Œã†
        is_recipe_channel = False
        if isinstance(message, discord.Message):
            is_recipe_channel = (message.channel.id == self.recipe_channel_id)
        elif isinstance(message, discord.InteractionMessage):
             # ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ã‚³ãƒãƒ³ãƒ‰ã®å ´åˆã¯ãƒãƒ£ãƒ³ãƒãƒ«IDã§åˆ¤å®š
             if message.channel:
                 is_recipe_channel = (message.channel.id == self.recipe_channel_id)


        try:
            if isinstance(message, discord.Message):
                try: await message.add_reaction(PROCESS_START_EMOJI)
                except discord.HTTPException: pass

            # --- â˜… ä¿®æ­£: ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å–å¾—ãƒ­ã‚¸ãƒƒã‚¯ (YouTube / Web) ---
            video_id_match = YOUTUBE_URL_REGEX.search(url)
            
            if video_id_match:
                # --- 1. YouTube Logic ---
                video_id = video_id_match.group(1)
                logging.info(f"Processing as YouTube URL (Video ID: {video_id})")
                try:
                    api = YouTubeTranscriptApi() 
                    fetched = await asyncio.to_thread(
                        api.fetch, 
                        video_id,
                        languages=['ja', 'en']
                    )
                    transcript_text = self._extract_transcript_text(fetched)
                    if not transcript_text:
                         logging.warning(f"å­—å¹•ãƒ†ã‚­ã‚¹ãƒˆãŒç©ºã§ã—ãŸ (Video ID: {video_id})")
                         if isinstance(message, discord.Message): error_reactions.add(TRANSCRIPT_NOT_FOUND_EMOJI)

                except (TranscriptsDisabled, NoTranscriptFound) as e:
                    logging.warning(f"å­—å¹•å–å¾—å¤±æ•— (Video ID: {video_id}): {e}")
                    if isinstance(message, discord.Message): error_reactions.add(TRANSCRIPT_NOT_FOUND_EMOJI)
                except Exception as e_trans:
                    logging.error(f"å­—å¹•å–å¾—ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ (Video ID: {video_id}): {e_trans}", exc_info=True) 
                    if isinstance(message, discord.Message): error_reactions.add(PROCESS_ERROR_EMOJI)
            
            elif is_recipe_channel and parse_url_with_readability:
                # --- 2. Webpage Logic (Recipe Channel Only) ---
                logging.info(f"Non-YouTube URL detected in Recipe channel. Parsing as webpage: {url}")
                try:
                    loop = asyncio.get_running_loop()
                    parsed_title, content_md = await loop.run_in_executor(
                        None, parse_url_with_readability, url
                    )
                    
                    if parsed_title and parsed_title != "No Title Found":
                        title_from_content = parsed_title
                    
                    if content_md and "URLã®å–å¾—ã«å¤±æ•—" not in content_md:
                        transcript_text = content_md # Webãƒšãƒ¼ã‚¸ã®Markdownã‚’ã€Œãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆã€ã¨ã—ã¦æ‰±ã†
                        logging.info(f"Webpage parsed successfully. Title: {parsed_title}")
                    else:
                        logging.warning(f"Webpage parsing failed or returned empty content for {url}")
                        if isinstance(message, discord.Message): error_reactions.add(TRANSCRIPT_NOT_FOUND_EMOJI)
                        
                except Exception as e_web:
                    logging.error(f"Webpage parsing failed with exception: {e_web}", exc_info=True)
                    if isinstance(message, discord.Message): error_reactions.add(PROCESS_ERROR_EMOJI)

            else:
                # --- 3. Invalid ---
                if not parse_url_with_readability and is_recipe_channel:
                     logging.error("Web recipe detected but web_parser is not available.")
                     if isinstance(message, discord.Message): error_reactions.add(PROCESS_ERROR_EMOJI)
                     raise ValueError("Web Parser not available")
                else:
                    if isinstance(message, discord.Message): error_reactions.add(INVALID_URL_EMOJI)
                    raise ValueError("Invalid URL: Non-YouTube URL in YouTube Summary channel")
            # --- â˜… ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å–å¾—ãƒ­ã‚¸ãƒƒã‚¯ã“ã“ã¾ã§ ---


            # --- AIè¦ç´„ ---
            concise_summary = "(è¦ç´„å¯¾è±¡ãªã—)"
            detail_summary = "(å¯¾è±¡å¤–)" # ãƒ¬ã‚·ãƒ”ã®å ´åˆã¯ä½¿ã‚ãªã„
            
            if transcript_text and self.gemini_model:
                try:
                    if is_recipe_channel:
                        # --- 2a. AI Recipe Logic ---
                        logging.info("Generating AI Recipe summary...")
                        recipe_prompt = (
                            "ä»¥ä¸‹ã®Webãƒšãƒ¼ã‚¸æœ¬æ–‡ã¾ãŸã¯YouTubeå‹•ç”»ã®æ–‡å­—èµ·ã“ã—ã‹ã‚‰ã€ãƒ¬ã‚·ãƒ”æƒ…å ±ï¼ˆææ–™ã¨ä½œã‚Šæ–¹ï¼‰ã‚’æŠ½å‡ºã—ã€ç°¡æ½”ãªMarkdownå½¢å¼ã§è¦ç´„ã—ã¦ãã ã•ã„ã€‚\n"
                            "ã€Œ## ææ–™ã€ã¨ã€Œ## ä½œã‚Šæ–¹ã€ã®2ã¤ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’å¿…ãšä½œæˆã—ã¦ãã ã•ã„ã€‚\n"
                            "ææ–™ã¯ç®‡æ¡æ›¸ãï¼ˆ-ï¼‰ã§ã€ä½œã‚Šæ–¹ã¯ç•ªå·ä»˜ããƒªã‚¹ãƒˆï¼ˆ1. ...ï¼‰ã§è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚\n"
                            "ãã‚Œä»¥å¤–ã®æƒ…å ±ï¼ˆå°å…¥ã€æ„Ÿæƒ³ãªã©ï¼‰ã¯å«ã‚ãªã„ã§ãã ã•ã„ã€‚\n\n"
                            f"--- æœ¬æ–‡/æ–‡å­—èµ·ã“ã— ---\n{transcript_text}"
                        )
                        try:
                            response = await asyncio.wait_for(self.gemini_model.generate_content_async(recipe_prompt), timeout=300)
                            if hasattr(response, 'text') and response.text.strip():
                                concise_summary = response.text.strip() # ãƒ¬ã‚·ãƒ”è¦ç´„ã‚’ concise_summary ã«æ ¼ç´
                            else:
                                concise_summary = "(ãƒ¬ã‚·ãƒ”è¦ç´„å¿œç­”ä¸æ­£)"
                                error_reactions.add(SUMMARY_ERROR_EMOJI)
                        except (Exception, asyncio.TimeoutError) as e_recipe:
                            logging.error(f"AI recipe summary failed: {e_recipe}", exc_info=True)
                            concise_summary = f"(ãƒ¬ã‚·ãƒ”è¦ç´„ã‚¨ãƒ©ãƒ¼: {type(e_recipe).__name__})"
                            error_reactions.add(SUMMARY_ERROR_EMOJI)

                    else:
                        # --- 2b. AI General YouTube Logic (existing) ---
                        logging.info("Generating AI General YouTube summaries...")
                        concise_prompt = (
                            "ä»¥ä¸‹ã®YouTubeå‹•ç”»ã®æ–‡å­—èµ·ã“ã—å…¨æ–‡ã‚’å…ƒã«ã€é‡è¦ãªãƒã‚¤ãƒ³ãƒˆã‚’3ï½5ç‚¹ã§ç°¡æ½”ã«ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚\n"
                            "è¦ç´„æœ¬æ–‡ã®ã¿ã‚’ç”Ÿæˆã—ã€å‰ç½®ãã‚„è¿”ç­”ã¯ä¸€åˆ‡å«ã‚ãªã„ã§ãã ã•ã„ã€‚\n\n"
                            f"--- æ–‡å­—èµ·ã“ã—å…¨æ–‡ ---\n{transcript_text}"
                        )
                        detail_prompt = (
                            "ä»¥ä¸‹ã®YouTubeå‹•ç”»ã®æ–‡å­—èµ·ã“ã—å…¨æ–‡ã‚’å…ƒã«ã€ãã®å†…å®¹ã‚’ç¶²ç¾…ã™ã‚‹è©³ç´°ã§åŒ…æ‹¬çš„ãªè¦ç´„ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\n"
                            "è¦ç´„æœ¬æ–‡ã®ã¿ã‚’ç”Ÿæˆã—ã€å‰ç½®ãã‚„è¿”ç­”ã¯ä¸€åˆ‡å«ã‚ãªã„ã§ãã ã•ã„ã€‚\n\n"
                            f"--- æ–‡å­—èµ·ã“ã—å…¨æ–‡ ---\n{transcript_text}"
                        )
                        tasks = [
                            self.gemini_model.generate_content_async(concise_prompt),
                            self.gemini_model.generate_content_async(detail_prompt)
                        ]
                        responses = await asyncio.gather(*[asyncio.wait_for(task, timeout=300) for task in tasks], return_exceptions=True)

                        if isinstance(responses[0], (Exception, asyncio.TimeoutError)):
                             concise_summary = f"(ç°¡æ½”ãªè¦ç´„ã‚¨ãƒ©ãƒ¼: {type(responses[0]).__name__})"
                             error_reactions.add(SUMMARY_ERROR_EMOJI)
                        elif hasattr(responses[0], 'text'): concise_summary = responses[0].text.strip()
                        else: concise_summary = "(ç°¡æ½”ãªè¦ç´„å¿œç­”ä¸æ­£)"; error_reactions.add(SUMMARY_ERROR_EMOJI)

                        if isinstance(responses[1], (Exception, asyncio.TimeoutError)):
                             detail_summary = f"(è©³ç´°ãªè¦ç´„ã‚¨ãƒ©ãƒ¼: {type(responses[1]).__name__})"
                             error_reactions.add(SUMMARY_ERROR_EMOJI)
                        elif hasattr(responses[1], 'text'): detail_summary = responses[1].text.strip()
                        else: detail_summary = "(è©³ç´°ãªè¦ç´„å¿œç­”ä¸æ­£)"; error_reactions.add(SUMMARY_ERROR_EMOJI)

                    if not error_reactions.intersection({SUMMARY_ERROR_EMOJI}): logging.info(f"AI summaries generated for {url}")

                except Exception as e_gather:
                    logging.error(f"AI summary gather failed: {e_gather}", exc_info=True)
                    concise_summary = detail_summary = "(AIè¦ç´„ãƒ—ãƒ­ã‚»ã‚¹ã‚¨ãƒ©ãƒ¼)"
                    if isinstance(message, discord.Message): error_reactions.add(SUMMARY_ERROR_EMOJI)

            elif not self.gemini_model: concise_summary = detail_summary = "(AIè¦ç´„æ©Ÿèƒ½ç„¡åŠ¹)"; error_reactions.add(SUMMARY_ERROR_EMOJI)
            elif not transcript_text: concise_summary = detail_summary = "(å­—å¹•/æœ¬æ–‡ãªã—ã®ãŸã‚è¦ç´„ä¸å¯)"

            # --- â˜… ä¿®æ­£: Discord Embed (ãƒ¬ã‚·ãƒ”ãƒãƒ£ãƒ³ãƒãƒ«ã®ã¿æŠ•ç¨¿) ---
            if is_recipe_channel:
                logging.info("Sending recipe summary to Discord channel.")
                title_for_embed = video_title if video_id else title_from_content
                if not title_for_embed: title_for_embed = "Recipe"
                
                try:
                    embed = discord.Embed(
                        title=f"ğŸ§‘â€ğŸ³ ãƒ¬ã‚·ãƒ”è¦ç´„ (AI): {title_for_embed}",
                        description=concise_summary, # ãƒ¬ã‚·ãƒ”è¦ç´„
                        color=discord.Color.orange(),
                        url=url
                    )
                    if isinstance(message, discord.Message):
                        await message.reply(embed=embed, mention_author=False)
                    elif isinstance(message, discord.InteractionMessage):
                         # ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ã‚³ãƒãƒ³ãƒ‰ã®å ´åˆã¯ followup ã§
                         interaction = getattr(message, 'interaction', None)
                         if interaction: await interaction.followup.send(embed=embed)
                except discord.HTTPException as e_discord:
                    logging.error(f"RecipeCog (YT): Discordã¸ã®è¦ç´„æŠ•ç¨¿å¤±æ•—: {e_discord}", exc_info=True)
            # --- â˜… ä¿®æ­£ã“ã“ã¾ã§ ---

            # --- â˜… ä¿®æ­£: ä¿å­˜æº–å‚™ (ã‚¿ã‚¤ãƒˆãƒ«æ±ºå®šãƒ­ã‚¸ãƒƒã‚¯) ---
            now = datetime.datetime.now(JST)
            daily_note_date = now.strftime('%Y-%m-%d')
            timestamp = now.strftime('%Y%m%d%H%M%S')
            video_info = {}

            if video_id:
                video_info = await self.get_video_info(video_id)
                video_title = video_info.get("title", f"YouTube_{video_id}")
            elif title_from_content:
                video_title = title_from_content # Webãƒ‘ãƒ¼ã‚µãƒ¼ã®ã‚¿ã‚¤ãƒˆãƒ«
            else:
                video_title = f"Untitled_{timestamp}"
                
            safe_title = re.sub(r'[\\/*?:"<>|]', "_", video_title)[:100]
            if not safe_title: safe_title = f"Untitled_{timestamp}"
            note_filename = f"{timestamp}-{safe_title}.md"
            note_filename_for_link = note_filename.replace('.md', '')
            # --- â˜… ä¿®æ­£ã“ã“ã¾ã§ ---

            # --- â˜… ä¿®æ­£: Obsidianç”¨ãƒãƒ¼ãƒˆå†…å®¹ (åˆ†å²) ---
            
            # ãƒ•ã‚©ãƒ«ãƒ€ã¨ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’æ±ºå®š
            if is_recipe_channel:
                save_folder = "/Recipes"
                daily_note_header = "## Recipes"
                gdoc_source_type = "Recipe"
            else:
                save_folder = "/YouTube"
                daily_note_header = "## YouTube Summaries"
                gdoc_source_type = "YouTube Transcript" # (YouTubeã®ã¿ãªã®ã§)

            note_content = (
                f"# {video_title}\n\n"
            )
            
            if video_id: # YouTubeã®å ´åˆ
                note_content += f'<iframe width="560" height="315" src="https://www.youtube.com/embed/{video_id}" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>\n\n'
            
            note_content += (
                f"- **URL:** {url}\n"
            )
            
            if video_id: # YouTubeã®å ´åˆ
                note_content += f"- **Channel:** {video_info.get('author_name', 'N/A')}\n"
            
            note_content += (
                f"- **Clipped:** {now.strftime('%Y-%m-%d %H:%M')}\n\n"
                f"[[{daily_note_date}]]\n\n"
                f"---\n\n"
            )

            if is_recipe_channel:
                note_content += f"## ãƒ¬ã‚·ãƒ”è¦ç´„ (AI)\n{concise_summary}\n"
                # (Webãƒ¬ã‚·ãƒ”ã®å ´åˆã€å…ƒæœ¬æ–‡(transcript_text)ã‚‚ä¿å­˜)
                if not video_id and transcript_text:
                     note_content += f"\n---\n\n## å…ƒè¨˜äº‹ (æœ¬æ–‡)\n{transcript_text[:10000]}...\n"
            else:
                # YouTube General
                note_content += f"## Concise Summary\n{concise_summary}\n\n"
                note_content += f"## Detailed Summary\n{detail_summary}\n\n"
                if transcript_text:
                     note_content += f"\n---\n\n## Full Transcript\n{transcript_text[:10000]}...\n"
            # --- â˜… ä¿®æ­£ã“ã“ã¾ã§ ---


            # --- Obsidianã¸ã®ä¿å­˜ (save_folder, daily_note_header ã‚’ä½¿ç”¨) ---
            if self.dbx:
                try:
                    note_path = f"{self.dropbox_vault_path}{save_folder}/{note_filename}"
                    await asyncio.to_thread(self.dbx.files_upload, note_content.encode('utf-8'), note_path, mode=WriteMode('add'))
                    logging.info(f"Summary saved to Obsidian note: {note_path}")

                    daily_note_path = f"{self.dropbox_vault_path}/DailyNotes/{daily_note_date}.md"
                    daily_note_content = ""
                    try:
                        _, res = await asyncio.to_thread(self.dbx.files_download, daily_note_path)
                        daily_note_content = res.content.decode('utf-8')
                    except ApiError as e_dn:
                        if isinstance(e_dn.error, DownloadError) and e_dn.error.is_path() and e_dn.error.get_path().is_not_found():
                            daily_note_content = f"# {daily_note_date}\n"
                        else: raise

                    link_path_part = save_folder.lstrip('/')
                    link_to_add = f"- [[{link_path_part}/{note_filename_for_link}|{video_title}]]" 
                    new_daily_content = update_section(daily_note_content, link_to_add, daily_note_header) # â˜… daily_note_header ã‚’ä½¿ç”¨

                    await asyncio.to_thread(self.dbx.files_upload, new_daily_content.encode('utf-8'), daily_note_path, mode=WriteMode('overwrite'))
                    logging.info(f"Daily note updated with link ({daily_note_header}): {daily_note_path}")
                    obsidian_save_success = True

                except ApiError as e_obs_api:
                    logging.error(f"Error saving to Obsidian (Dropbox API): {e_obs_api}", exc_info=True)
                    error_reactions.add(SAVE_ERROR_EMOJI)
                except Exception as e_obs_other:
                    logging.error(f"Error saving to Obsidian (Other): {e_obs_other}", exc_info=True)
                    error_reactions.add(SAVE_ERROR_EMOJI)
            else:
                logging.error("Dropbox client not available. Skipping Obsidian save.")
                error_reactions.add(SAVE_ERROR_EMOJI)

            # --- Google Docsã¸ã®ä¿å­˜ ---
            if google_docs_enabled:
                gdoc_text_to_append = ""
                
                if is_recipe_channel:
                    gdoc_text_to_append = f"## ãƒ¬ã‚·ãƒ”è¦ç´„ (AI)\n{concise_summary}"
                elif transcript_text: # General YouTube
                    gdoc_text_to_append = transcript_text
                elif video_id: # YouTube (ã‚¨ãƒ©ãƒ¼)
                    error_reason = "(å­—å¹•ãªã—ã¾ãŸã¯å–å¾—å¤±æ•—)"
                    if TRANSCRIPT_NOT_FOUND_EMOJI in error_reactions: error_reason = "(å­—å¹•ãªã—ã¾ãŸã¯å–å¾—å¤±æ•—)"
                    if PROCESS_ERROR_EMOJI in error_reactions: error_reason = "(å­—å¹•å–å¾—ã‚¨ãƒ©ãƒ¼)"
                    gdoc_text_to_append = error_reason
                    gdoc_source_type = "YouTube Link (No Transcript)" # gdoc_source_type ã‚’ä¸Šæ›¸ã

                if gdoc_text_to_append:
                    try:
                        await append_text_to_doc_async(
                            text_to_append=gdoc_text_to_append,
                            source_type=gdoc_source_type, # â˜… gdoc_source_type ã‚’ä½¿ç”¨
                            url=url,
                            title=video_title
                        )
                        gdoc_save_success = True
                        logging.info(f"Data ({gdoc_source_type}) sent to Google Docs for {url}")
                    except Exception as e_gdoc:
                        logging.error(f"Failed to send data to Google Docs for {url}: {e_gdoc}", exc_info=True)
                        error_reactions.add(GOOGLE_DOCS_ERROR_EMOJI)

            # --- æœ€çµ‚ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ ---
            if isinstance(message, discord.Message):
                if obsidian_save_success:
                    if not error_reactions:
                        await message.add_reaction(PROCESS_COMPLETE_EMOJI)
                    else:
                        await message.add_reaction(PROCESS_COMPLETE_EMOJI)
                        for reaction in error_reactions:
                            try: await message.add_reaction(reaction)
                            except discord.HTTPException: pass
                else:
                    final_reactions = error_reactions if error_reactions else {PROCESS_ERROR_EMOJI}
                    for reaction in final_reactions:
                        try: await message.add_reaction(reaction)
                        except discord.HTTPException: pass

        except ValueError as e_val:
             logging.warning(f"Processing stopped due to ValueError: {e_val}") # warningã«å¤‰æ›´
             if isinstance(message, discord.Message):
                try: await message.add_reaction(INVALID_URL_EMOJI) # é©åˆ‡ãªã‚¨ãƒ©ãƒ¼
                except discord.HTTPException: pass
        except Exception as e:
            logging.error(f"YouTube/Recipeå‡¦ç†å…¨ä½“ã§ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            if isinstance(message, discord.Message):
                try: await message.add_reaction(PROCESS_ERROR_EMOJI)
                except discord.HTTPException: pass
            elif isinstance(message, discord.InteractionMessage):
                interaction = getattr(message, 'interaction', None)
                if interaction:
                    try: await interaction.followup.send(f"âŒ å‡¦ç†ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: `{type(e).__name__}`", ephemeral=True)
                    except discord.HTTPException: pass

            if google_docs_enabled:
                try:
                    error_text = f"YouTube/Recipeå‡¦ç†å…¨ä½“ã®ã‚¨ãƒ©ãƒ¼\nURL: {url}\nError: {type(e).__name__}: {e}"
                    title_for_error = video_title if video_title != "Untitled" else f"URL_{video_id or 'Unknown'}"
                    await append_text_to_doc_async(error_text, "Processing Error", url, title_for_error)
                except Exception as e_gdoc_err:
                     logging.error(f"Failed to record processing error to Google Docs: {e_gdoc_err}")

        finally:
            if isinstance(message, discord.Message):
                try: await message.remove_reaction(PROCESS_START_EMOJI, self.bot.user)
                except discord.HTTPException: pass

    # --- ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ã‚³ãƒãƒ³ãƒ‰ (å¤‰æ›´ãªã—) ---
    @app_commands.command(name="yt_summary", description="[æ‰‹å‹•] YouTubeå‹•ç”»URLã‚’Obsidian/Google Docsã«ä¿å­˜ã—ã¾ã™ã€‚")
    @app_commands.describe(url="å‡¦ç†ã—ãŸã„YouTubeå‹•ç”»ã®URL")
    async def yt_summary_command(self, interaction: discord.Interaction, url: str):
        if not self.is_ready:
             await interaction.response.send_message("âŒ YouTube CogãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚", ephemeral=True)
             return
             
        # â˜… ä¿®æ­£: ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ã‚³ãƒãƒ³ãƒ‰ãŒã©ã¡ã‚‰ã®ãƒãƒ£ãƒ³ãƒãƒ«ã§ä½¿ã‚ã‚ŒãŸã‹åˆ¤å®š
        if interaction.channel_id not in (self.youtube_summary_channel_id, self.recipe_channel_id):
             await interaction.response.send_message(f"âŒ ã“ã®ã‚³ãƒãƒ³ãƒ‰ã¯ <#{self.youtube_summary_channel_id}> ã¾ãŸã¯ <#{self.recipe_channel_id}> ã§ã®ã¿å®Ÿè¡Œã§ãã¾ã™ã€‚", ephemeral=True)
             return

        await interaction.response.defer(ephemeral=False, thinking=True)
        message_proxy = await interaction.original_response()

        class TempMessage:
             def __init__(self, proxy, channel): # â˜… channel ã‚’å—ã‘å–ã‚‹
                 self.id = proxy.id; self.reactions = []; self.channel = channel; self.jump_url = proxy.jump_url; self._proxy = proxy; self.content=proxy.content
                 self.interaction = interaction # â˜… interaction ã‚’ä¿æŒ
             async def add_reaction(self, emoji):
                 try: await self._proxy.add_reaction(emoji)
                 except: pass
             async def remove_reaction(self, emoji, user):
                 try: await self._proxy.remove_reaction(emoji, user)
                 except: pass

        # â˜… ä¿®æ­£: TempMessage ã« interaction.channel ã‚’æ¸¡ã™
        await self._perform_summary(url=url, message=TempMessage(message_proxy, interaction.channel))

    # --- get_video_info (å¤‰æ›´ãªã—) ---
    async def get_video_info(self, video_id: str) -> dict:
        url = f"https://www.youtube.com/oembed?url=https://www.youtube.com/watch?v={video_id}&format=json"
        try:
            headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'}
            async with self.session.get(url, headers=headers, timeout=10) as response:
                if response.status == 200:
                    try:
                        data = await response.json()
                        title = data.get("title")
                        author_name = data.get("author_name")
                        if title and author_name:
                            return {"title": title, "author_name": author_name}
                        else:
                            logging.warning(f"oEmbed missing title/author for {video_id}. Data: {data}")
                            return {"title": f"YouTube_{video_id}", "author_name": "N/A"}
                    except aiohttp.ContentTypeError:
                         text = await response.text()
                         logging.warning(f"oEmbed response not JSON for {video_id}. Text: {text[:100]}")
                         return {"title": f"YouTube_{video_id}", "author_name": "N/A"}
                else:
                    text = await response.text()
                    logging.warning(f"oEmbed failed: Status {response.status} for {video_id}. Text: {text[:100]}")
                    return {"title": f"YouTube_{video_id}", "author_name": "N/A"}
        except asyncio.TimeoutError:
            logging.warning(f"oEmbed request timed out for {video_id}")
        except aiohttp.ClientError as e:
            logging.warning(f"oEmbed client error for {video_id}: {e}")
        except Exception as e:
            logging.warning(f"oEmbed unexpected error for {video_id}: {e}")
        return {"title": f"YouTube_{video_id}", "author_name": "N/A"}


async def setup(bot: commands.Bot):
    """Cogã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
    # â˜… ä¿®æ­£: ã©ã¡ã‚‰ã‹ã®ãƒãƒ£ãƒ³ãƒãƒ«IDãŒã‚ã‚Œã°ãƒ­ãƒ¼ãƒ‰ã™ã‚‹
    youtube_channel_id = int(os.getenv("YOUTUBE_SUMMARY_CHANNEL_ID", 0))
    recipe_channel_id = int(os.getenv("RECIPE_CHANNEL_ID", 0))
    
    if youtube_channel_id == 0 and recipe_channel_id == 0:
        logging.error("YouTubeCog: YOUTUBE_SUMMARY_CHANNEL_ID ã¨ RECIPE_CHANNEL_ID ãŒä¸¡æ–¹ã¨ã‚‚è¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚Cogã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã›ã‚“ã€‚")
        return
        
    cog_instance = YouTubeCog(bot)
    if cog_instance.is_ready:
        await bot.add_cog(cog_instance)
        logging.info("YouTubeCog (and Recipe) loaded successfully.")
    else:
        logging.error("YouTubeCog failed to initialize properly and was not loaded.")
        del cog_instance