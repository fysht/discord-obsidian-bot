import os
import discord
from discord.ext import commands, tasks
from discord import app_commands
import logging
import json
from datetime import datetime, time
import zoneinfo
import io
import asyncio
import googlemaps
from geopy.distance import great_circle
import re

# Google Drive API
from google.oauth2.credentials import Credentials
from google.auth.transport.requests import Request
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseDownload, MediaIoBaseUpload

from utils.obsidian_utils import update_section

# --- å®šæ•°å®šç¾© ---
JST = zoneinfo.ZoneInfo("Asia/Tokyo")
TOKEN_FILE = 'token.json'
SCOPES = ['https://www.googleapis.com/auth/drive']
DATE_REGEX = re.compile(r'^\d{4}-\d{2}-\d{2}$')

ACTIVITY_TYPE_MAP = {
    "IN_PASSENGER_VEHICLE": "è»Šã§ã®ç§»å‹•",
    "WALKING": "å¾’æ­©ã§ã®ç§»å‹•",
    "CYCLING": "è‡ªè»¢è»Šã§ã®ç§»å‹•",
    "RUNNING": "ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°",
    "IN_BUS": "ãƒã‚¹ã§ã®ç§»å‹•",
    "IN_TRAIN": "é›»è»Šã§ã®ç§»å‹•",
    "IN_SUBWAY": "åœ°ä¸‹é‰„ã§ã®ç§»å‹•",
    "IN_TRAM": "è·¯é¢é›»è»Šã§ã®ç§»å‹•",
    "IN_FERRY": "ãƒ•ã‚§ãƒªãƒ¼ã§ã®ç§»å‹•",
    "FLYING": "é£›è¡Œæ©Ÿã§ã®ç§»å‹•",
    "STILL": "é™æ­¢",
    "UNKNOWN": "ä¸æ˜ãªç§»å‹•"
}

class LocationLogCog(commands.Cog):
    def __init__(self, bot: commands.Bot):
        self.bot = bot
        # è‡ªå‹•é€šçŸ¥å…ˆã‚’MEMO_CHANNEL_IDã«å¤‰æ›´
        self.memo_channel_id = int(os.getenv("MEMO_CHANNEL_ID", 0))
        self.drive_folder_id = os.getenv("GOOGLE_DRIVE_FOLDER_ID")
        
        self.home_coordinates = self._parse_coordinates(os.getenv("HOME_COORDINATES"))
        self.work_coordinates = self._parse_coordinates(os.getenv("WORK_COORDINATES"))
        self.exclude_radius_meters = int(os.getenv("EXCLUDE_RADIUS_METERS", 500))
        self.google_places_api_key = os.getenv("GOOGLE_PLACES_API_KEY")
        
        self.gmaps = googlemaps.Client(key=self.google_places_api_key) if self.google_places_api_key else None
        
        # æ¯æ—¥ 23:50 ã«è‡ªå‹•ã§å‡¦ç†ã‚’é–‹å§‹ã™ã‚‹
        self.process_timeline_json.start()

    def cog_unload(self):
        self.process_timeline_json.cancel()

    # --- ãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒ¡ã‚½ãƒƒãƒ‰ ---
    def _get_place_name_from_id(self, place_id: str) -> str:
        if not self.gmaps: return f"å ´æ‰€ID: {place_id}"
        try:
            place_details = self.gmaps.place(place_id=place_id, language='ja')
            if place_details and 'result' in place_details and 'name' in place_details['result']:
                return place_details['result']['name']
        except Exception as e:
            logging.error(f"Places APIã‹ã‚‰ã®åå‰å–å¾—ã«å¤±æ•—: {e}")
        return f"å ´æ‰€ID: {place_id}"

    def _parse_coordinates(self, coord_str: str | None) -> tuple[float, float] | None:
        if not coord_str: return None
        try:
            lat, lon = map(float, coord_str.split(','))
            return (lat, lon)
        except (ValueError, TypeError):
            return None

    def _format_duration(self, duration_seconds: float) -> str:
        minutes = int(duration_seconds / 60)
        if minutes < 1: return "1åˆ†æœªæº€"
        hours, minutes = divmod(minutes, 60)
        if hours > 0: return f"{hours}æ™‚é–“{minutes}åˆ†"
        return f"{minutes}åˆ†"

    def _parse_iso_timestamp(self, ts_str: str) -> datetime | None:
        try:
            if ts_str.count(':') == 3:
                ts_str = ts_str[::-1].replace(':', '', 1)[::-1]
            return datetime.fromisoformat(ts_str)
        except (ValueError, TypeError): return None

    # --- Google Drive API é–¢é€£ãƒ¡ã‚½ãƒƒãƒ‰ ---
    def _get_drive_service(self):
        creds = None
        if os.path.exists(TOKEN_FILE):
            try: creds = Credentials.from_authorized_user_file(TOKEN_FILE, SCOPES)
            except: pass
        if not creds or not creds.valid:
            if creds and creds.expired and creds.refresh_token:
                try: creds.refresh(Request()); open(TOKEN_FILE,'w').write(creds.to_json())
                except: return None
            else: return None
        return build('drive', 'v3', credentials=creds)

    def _find_file_recursive(self, service, parent_id, name, mime_type=None):
        query = f"'{parent_id}' in parents and name = '{name}' and trashed = false"
        if mime_type: query += f" and mimeType = '{mime_type}'"
        res = service.files().list(q=query, fields="files(id)").execute()
        files = res.get('files', [])
        return files[0]['id'] if files else None

    def _find_folder_in_root(self, service, name):
        query = f"'root' in parents and name = '{name}' and mimeType = 'application/vnd.google-apps.folder' and trashed = false"
        res = service.files().list(q=query, fields="files(id)").execute()
        files = res.get('files', [])
        return files[0]['id'] if files else None

    def _get_unprocessed_json(self, service, folder_id):
        # â˜… å‡¦ç†å¾…ã¡ã®ã€Œã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³.jsonã€ã‚’æ¢ã™ã‚ˆã†ã«ä¿®æ­£
        query = f"'{folder_id}' in parents and name contains 'ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³.json' and not name contains 'å‡¦ç†æ¸ˆã¿_' and trashed = false"
        res = service.files().list(q=query, fields="files(id, name)").execute()
        return res.get('files', [])

    def _get_latest_timeline_json(self, service, folder_id):
        # â˜… å‡¦ç†æ¸ˆã¿ãƒ»æœªå‡¦ç†å•ã‚ãšã€ä¸€ç•ªæ–°ã—ã„ã€Œã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³.jsonã€ã‚’å–å¾—ã™ã‚‹ã‚ˆã†ä¿®æ­£
        query = f"'{folder_id}' in parents and name contains 'ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³.json' and trashed = false"
        res = service.files().list(q=query, fields="files(id, name, createdTime)", orderBy="createdTime desc").execute()
        files = res.get('files', [])
        return files[0] if files else None

    def _rename_file(self, service, file_id, new_name):
        service.files().update(fileId=file_id, body={'name': new_name}).execute()

    def _read_json(self, service, file_id):
        fh = io.BytesIO()
        downloader = MediaIoBaseDownload(fh, service.files().get_media(fileId=file_id))
        done = False
        while not done: _, done = downloader.next_chunk()
        return json.loads(fh.getvalue().decode('utf-8'))

    def _read_text(self, service, file_id):
        fh = io.BytesIO()
        downloader = MediaIoBaseDownload(fh, service.files().get_media(fileId=file_id))
        done = False
        while not done: _, done = downloader.next_chunk()
        return fh.getvalue().decode('utf-8')

    def _update_text(self, service, file_id, content):
        service.files().update(fileId=file_id, media_body=MediaIoBaseUpload(io.BytesIO(content.encode('utf-8')), mimetype='text/markdown')).execute()

    def _create_text(self, service, parent_id, name, content):
        service.files().create(body={'name': name, 'parents': [parent_id], 'mimeType': 'text/markdown'}, media_body=MediaIoBaseUpload(io.BytesIO(content.encode('utf-8')), mimetype='text/markdown')).execute()

    # --- JSONãƒ‡ãƒ¼ã‚¿è§£æã®å…±é€šãƒ­ã‚¸ãƒƒã‚¯ ---
    def _extract_logs_from_json(self, data: dict, target_date_str: str) -> dict:
        """æŒ‡å®šã•ã‚ŒãŸæ—¥ä»˜ï¼ˆtarget_date_strï¼‰ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’æŠ½å‡ºã—ã¦ãƒ†ã‚­ã‚¹ãƒˆåŒ–ã™ã‚‹"""
        segments = data.get("semanticSegments", [])
        if not segments: return None

        events_by_date = {}
        for seg in segments:
            start_time = self._parse_iso_timestamp(seg.get("startTime", ''))
            end_time = self._parse_iso_timestamp(seg.get("endTime", ''))
            if not start_time or not end_time: continue

            event_date = start_time.astimezone(JST).date()
            date_str = event_date.strftime('%Y-%m-%d')

            # æŒ‡å®šã•ã‚ŒãŸæ—¥ä»˜ä»¥å¤–ã¯å®Œå…¨ã«ç„¡è¦–ã™ã‚‹
            if date_str != target_date_str: continue

            events_by_date.setdefault(date_str, [])
            duration_seconds = (end_time - start_time).total_seconds()
            duration_formatted = self._format_duration(duration_seconds)
            event = {"start": start_time, "end": end_time}

            if (visit_data := seg.get("visit")):
                top_candidate = visit_data.get("topCandidate", {})
                lat_lng_str = top_candidate.get("placeLocation", {}).get("latLng")
                if not lat_lng_str: continue
                try:
                    lat_str, lon_str = lat_lng_str.replace('Â°', '').split(',')
                    place_coords = (float(lat_str), float(lon_str.strip()))
                except (ValueError, IndexError): continue
                
                place_name = "ä¸æ˜ãªå ´æ‰€"
                place_id = top_candidate.get('placeId')
                if place_id: place_name = self._get_place_name_from_id(place_id)
                
                if self.home_coordinates and great_circle(place_coords, self.home_coordinates).meters < self.exclude_radius_meters: place_name = "è‡ªå®…"
                elif self.work_coordinates and great_circle(place_coords, self.work_coordinates).meters < self.exclude_radius_meters: place_name = "å‹¤å‹™å…ˆ"
                
                event.update({"type": "stay", "name": place_name, "duration": duration_formatted})
                events_by_date[date_str].append(event)
            
            elif (activity_data := seg.get("activity")):
                activity_type = activity_data.get("topCandidate", {}).get("type", "UNKNOWN")
                distance_m = activity_data.get("distanceMeters", 0)
                distance_km_str = f" (ç´„{distance_m / 1000:.1f}km)" if distance_m > 0 else ""
                event.update({"type": "move", "activity": ACTIVITY_TYPE_MAP.get(activity_type, "ä¸æ˜ãªç§»å‹•"), "duration": duration_formatted, "distance": distance_km_str})
                events_by_date[date_str].append(event)

        # ãƒ†ã‚­ã‚¹ãƒˆæ•´å½¢
        logs_by_date = {}
        for d_str, events in sorted(events_by_date.items()):
            if not events: continue
            sorted_events = sorted(events, key=lambda x: x['start'])
            log_entries, last_place = [], None
            
            for event in sorted_events:
                start_str_jst = event['start'].astimezone(JST).strftime('%H:%M')
                if event['type'] == 'stay':
                    if last_place is not None: log_entries.append(f"- **{start_str_jst}** {event['name']}ã«åˆ°ç€")
                    log_entries.append(f"- **{start_str_jst} - {event['end'].astimezone(JST).strftime('%H:%M')}** ({event['duration']}) æ»åœ¨: {event['name']}")
                    last_place = event['name']
                elif event['type'] == 'move':
                    if last_place: log_entries.append(f"- **{start_str_jst}** {last_place}ã‚’å‡ºç™º")
                    log_entries.append(f"- **{start_str_jst} - {event['end'].astimezone(JST).strftime('%H:%M')}** ({event['duration']}) {event['activity']}{event['distance']}")
                    last_place = None
            
            logs_by_date[d_str] = "\n".join(log_entries)

        return logs_by_date

    # --- Obsidianæ›¸ãè¾¼ã¿ã®å…±é€šãƒ­ã‚¸ãƒƒã‚¯ ---
    async def _write_to_obsidian(self, service, loop, date_str: str, log_text: str):
        daily_folder = await loop.run_in_executor(None, self._find_file_recursive, service, self.drive_folder_id, "DailyNotes", "application/vnd.google-apps.folder")
        if not daily_folder:
            meta = {'name': 'DailyNotes', 'mimeType': 'application/vnd.google-apps.folder', 'parents': [self.drive_folder_id]}
            folder_obj = await loop.run_in_executor(None, lambda: service.files().create(body=meta, fields='id').execute())
            daily_folder = folder_obj.get('id')

        daily_file = await loop.run_in_executor(None, self._find_file_recursive, service, daily_folder, f"{date_str}.md")
        
        cur = ""
        if daily_file:
            cur = await loop.run_in_executor(None, self._read_text, service, daily_file)
        else:
            # å¤‰æ›´ï¼šãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼ã‚’ä»–ã®æ©Ÿèƒ½ã¨çµ±ä¸€ã—ã€è¦‹å‡ºã—ã‚’è‹±èªã«å¤‰æ›´
            cur = f"---\ndate: {date_str}\n---\n\n# Daily Note {date_str}\n\n## ğŸ“ Location History\n\n"
        
        # å¤‰æ›´ï¼šè¦‹å‡ºã—ã‚’è‹±èªã«å¤‰æ›´
        new = update_section(cur, log_text, "## ğŸ“ Location History")
        
        if daily_file:
            await loop.run_in_executor(None, self._update_text, service, daily_file, new)
        else:
            await loop.run_in_executor(None, self._create_text, service, daily_folder, f"{date_str}.md", new)


    # â–¼ æ¯æ—¥ 23:50 ã«å…¨è‡ªå‹•ã§å®Ÿè¡Œã•ã‚Œã‚‹å‡¦ç†ï¼ˆå½“æ—¥åˆ†ã®ã¿ï¼‰
    @tasks.loop(time=time(hour=23, minute=50, tzinfo=JST))
    async def process_timeline_json(self):
        logging.info("ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³JSONã®è‡ªå‹•å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™ã€‚")
        loop = asyncio.get_running_loop()
        service = await loop.run_in_executor(None, self._get_drive_service)
        if not service: return

        # é€ä¿¡å…ˆã‚’ãƒ¡ãƒ¢ãƒãƒ£ãƒ³ãƒãƒ«ã«ã™ã‚‹
        channel = self.bot.get_channel(self.memo_channel_id)
        today_str = datetime.now(JST).strftime('%Y-%m-%d')

        # ä¿å­˜å…ˆãƒ•ã‚©ãƒ«ãƒ€ã¯ã€ŒTimelineã€ã®ã¾ã¾ï¼ˆå¤‰æ›´ãªã—ï¼‰
        timeline_folder_id = await loop.run_in_executor(None, self._find_folder_in_root, service, "Timeline")
        if not timeline_folder_id: return

        json_files = await loop.run_in_executor(None, self._get_unprocessed_json, service, timeline_folder_id)
        if not json_files: return 

        for file_info in json_files:
            file_id = file_info['id']
            file_name = file_info['name']
            
            try:
                data = await loop.run_in_executor(None, self._read_json, service, file_id)
            except Exception as e:
                logging.error(f"JSONèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
                continue

            # ä»Šæ—¥ã®æ—¥ä»˜ï¼ˆtoday_strï¼‰ã ã‘ã‚’æŠ½å‡ºã™ã‚‹
            logs_by_date = self._extract_logs_from_json(data, today_str)

            if logs_by_date and today_str in logs_by_date:
                # æŠ½å‡ºã§ããŸå ´åˆã®ã¿Obsidianã«æ›¸ãè¾¼ã‚€
                await self._write_to_obsidian(service, loop, today_str, logs_by_date[today_str])

            # éå»ã®ãƒ‡ãƒ¼ã‚¿ãŒå«ã¾ã‚Œã¦ã„ã‚ˆã†ãŒã„ã¾ã„ãŒã€ä»Šæ—¥ãƒã‚§ãƒƒã‚¯ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã¯ã€Œå‡¦ç†æ¸ˆã¿ã€ã«ã—ã¦äºŒé‡å‡¦ç†ã‚’é˜²ã
            timestamp = datetime.now(JST).strftime('%Y%m%d_%H%M%S')
            await loop.run_in_executor(None, self._rename_file, service, file_id, f"å‡¦ç†æ¸ˆã¿_{timestamp}_{file_name}")
            
            if channel and logs_by_date:
                await channel.send(f"ğŸ“ æœ¬æ—¥ã®ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³å±¥æ­´ã‚’è§£æã—ã¦Obsidianã«ä¿å­˜ã—ã¾ã—ãŸï¼")


    # â–¼ æ‰‹å‹•ã§éå»ã®ãƒ‡ãƒ¼ã‚¿ã‚’åŒæœŸã™ã‚‹ã‚³ãƒãƒ³ãƒ‰
    @app_commands.command(name="location_sync", description="éå»ã®ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³å±¥æ­´ã‚’æŒ‡å®šã—ã¦æ‰‹å‹•ã§åŒæœŸã—ã¾ã™ã€‚")
    @app_commands.describe(target_date="åŒæœŸã—ãŸã„æ—¥ä»˜ (ä¾‹: 2026-02-15)")
    async def sync_location_manual(self, interaction: discord.Interaction, target_date: str):
        await interaction.response.defer(ephemeral=False)
        
        if not DATE_REGEX.match(target_date):
            await interaction.followup.send("âŒ æ—¥ä»˜ã®å½¢å¼ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“ã€‚(ä¾‹: 2026-02-15)")
            return

        loop = asyncio.get_running_loop()
        service = await loop.run_in_executor(None, self._get_drive_service)
        if not service:
            await interaction.followup.send("âŒ Google Drive APIã®èªè¨¼ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            return

        timeline_folder_id = await loop.run_in_executor(None, self._find_folder_in_root, service, "Timeline")
        if not timeline_folder_id:
            await interaction.followup.send("âŒ ãƒã‚¤ãƒ‰ãƒ©ã‚¤ãƒ–ã« `Timeline` ãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            return

        # å‡¦ç†æ¸ˆã¿ãƒ»æœªå‡¦ç†å•ã‚ãšã€ä¸€ç•ªæ–°ã—ã„ ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³.json ã‚’å–å¾—
        latest_file = await loop.run_in_executor(None, self._get_latest_timeline_json, service, timeline_folder_id)
        if not latest_file:
            await interaction.followup.send("âŒ `Timeline` ãƒ•ã‚©ãƒ«ãƒ€ã«JSONãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            return

        # èª­ã¿è¾¼ã¿ã¨è§£æ
        try:
            data = await loop.run_in_executor(None, self._read_json, service, latest_file['id'])
        except Exception as e:
            await interaction.followup.send(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚({e})")
            return

        logs_by_date = self._extract_logs_from_json(data, target_date)
        if not logs_by_date or target_date not in logs_by_date:
            await interaction.followup.send(f"âš ï¸ å‚ç…§ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ`{latest_file['name']}`ï¼‰å†…ã« **{target_date}** ã®ç§»å‹•ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            return

        # Obsidianã¸ã®æ›¸ãè¾¼ã¿
        await self._write_to_obsidian(service, loop, target_date, logs_by_date[target_date])
        await interaction.followup.send(f"âœ… **{target_date}** ã®ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³å±¥æ­´ã‚’æ‰‹å‹•åŒæœŸã—ã¦ä¿å­˜ã—ã¾ã—ãŸï¼\n(å‚ç…§ãƒ•ã‚¡ã‚¤ãƒ«: `{latest_file['name']}`)")


    @process_timeline_json.before_loop
    async def before_process(self):
        await self.bot.wait_until_ready()

async def setup(bot): await bot.add_cog(LocationLogCog(bot))