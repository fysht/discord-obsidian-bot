import os
import datetime
import re
import asyncio
import logging
import zoneinfo
import aiohttp
import json
from google import genai
from web_parser import parse_url_with_readability

JST = zoneinfo.ZoneInfo("Asia/Tokyo")

class WebClipService:
    def __init__(self, drive_service, gemini_api_key):
        self.drive_service = drive_service
        self.gemini_client = None
        if gemini_api_key:
            self.gemini_client = genai.Client(api_key=gemini_api_key)

    async def get_youtube_info(self, url):
        """YouTubeã®oembed APIã‹ã‚‰ã‚¿ã‚¤ãƒˆãƒ«ã¨ãƒãƒ£ãƒ³ãƒãƒ«åã‚’å–å¾—"""
        oembed_url = f"https://www.youtube.com/oembed?url={url}&format=json"
        
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(oembed_url) as response:
                    if response.status == 200:
                        data = await response.json()
                        return {
                            "title": data.get("title"),
                            "author_name": data.get("author_name")
                        }
        except Exception as e:
            logging.error(f"YouTube Info Fetch Error: {e}")
        
        return None

    def _is_recipe(self, title, url, text=""):
        """ã‚¿ã‚¤ãƒˆãƒ«ã€URLã€æœ¬æ–‡ã‹ã‚‰ãƒ¬ã‚·ãƒ”ã‹ã©ã†ã‹ã‚’åˆ¤å®šã™ã‚‹"""
        # 1. ãƒ‰ãƒ¡ã‚¤ãƒ³åˆ¤å®š (ä»£è¡¨çš„ãªãƒ¬ã‚·ãƒ”ã‚µã‚¤ãƒˆ)
        recipe_domains = [
            'cookpad.com', 'kurashiru.com', 'delishkitchen.tv', 
            'macaro-ni.jp', 'orangepage.net', 'lettuceclub.net', 
            'erecipe.woman.excite.co.jp', 'kyounoryouri.jp', 'ajinomoto.co.jp'
        ]
        if any(d in url for d in recipe_domains):
            return True

        # 2. ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ¤å®š (ã‚¿ã‚¤ãƒˆãƒ«)
        keywords = ['ãƒ¬ã‚·ãƒ”', 'ä½œã‚Šæ–¹', 'çŒ®ç«‹', 'Recipe', 'Cooking', 'ææ–™', 'ä¸‹ã”ã—ã‚‰ãˆ']
        if any(k in title for k in keywords):
            return True
            
        # 3. æœ¬æ–‡åˆ¤å®š (Webè¨˜äº‹ã®å ´åˆ)
        if text and 'ææ–™' in text and 'ä½œã‚Šæ–¹' in text:
            return True

        return False

    async def _get_fallback_title(self, url):
        """Playwrightã§ã®å–å¾—ãŒå¤±æ•—ã—ãŸéš›ã«ã€è»½é‡ãªHTTPé€šä¿¡ã§ã‚¿ã‚¤ãƒˆãƒ«ã®ã¿ã‚’å–å¾—ã™ã‚‹"""
        try:
            async with aiohttp.ClientSession() as session:
                # ä¸€èˆ¬çš„ãªãƒ–ãƒ©ã‚¦ã‚¶ã‹ã‚‰ã®ã‚¢ã‚¯ã‚»ã‚¹ã«è¦‹ã›ã‹ã‘ã‚‹
                headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'}
                async with session.get(url, headers=headers, timeout=10) as response:
                    if response.status == 200:
                        html = await response.text()
                        # æ­£è¦è¡¨ç¾ã§ <title> ã‚¿ã‚°ã®ä¸­èº«ã ã‘ã‚’æŠ½å‡º
                        match = re.search(r'<title[^>]*>(.*?)</title>', html, re.IGNORECASE | re.DOTALL)
                        if match:
                            return match.group(1).strip()
        except Exception as e:
            logging.error(f"Fallback Title Fetch Error: {e}")
        
        return "Untitled"

    async def process_url(self, url, message_content, trigger_message_obj):
        """
        URLã‚’å‡¦ç†ã—ã€Driveã«ä¿å­˜ã—ã€çµæœã®æ¦‚è¦ã‚’è¿”ã™
        """
        is_youtube = "youtube.com" in url or "youtu.be" in url
        source_type = "YouTube" if is_youtube else "WebClip"
        
        title = "Untitled"
        raw_text = ""
        author_name = ""

        # 1. æƒ…å ±å–å¾—
        if is_youtube:
            yt_info = await self.get_youtube_info(url)
            if yt_info:
                title = yt_info.get("title", "Untitled")
                author_name = yt_info.get("author_name", "")
            else:
                try:
                    title, _ = await parse_url_with_readability(url)
                except:
                    title = "YouTube Video"
        else:
            try:
                # 35ç§’ã§ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã™ã‚‹ã‚ˆã†ã«è¨­å®š
                title, raw_text = await asyncio.wait_for(parse_url_with_readability(url), timeout=35.0)
                
                # ã‚¿ã‚¤ãƒˆãƒ«ãŒæ­£å¸¸ã«å–ã‚Œãªã‹ã£ãŸå ´åˆã¯äºˆå‚™ãƒ¡ã‚½ãƒƒãƒ‰ã§å–å¾—
                if not title or title == "No Title Found":
                    title = await self._get_fallback_title(url)
                    
            except asyncio.TimeoutError:
                logging.warning(f"WebClip: Parse Timeout for URL: {url}")
                # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆæ™‚ã¯äºˆå‚™ãƒ¡ã‚½ãƒƒãƒ‰ã§ã‚¿ã‚¤ãƒˆãƒ«ã ã‘å–å¾—ã—ã€æœ¬æ–‡ã¯å›ºå®šãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«ã™ã‚‹
                title = await self._get_fallback_title(url)
                raw_text = "â€»ãƒšãƒ¼ã‚¸ã®èª­ã¿è¾¼ã¿ã«æ™‚é–“ãŒã‹ã‹ã£ãŸãŸã‚ã€æœ¬æ–‡ã¯å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚\n"
                
            except Exception as e:
                logging.error(f"WebClip: Parse Error: {e}")
                # ãã®ä»–ã®ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚ã‚¿ã‚¤ãƒˆãƒ«ã ã‘å–å¾—ã™ã‚‹
                title = await self._get_fallback_title(url)
                raw_text = f"â€»ãƒšãƒ¼ã‚¸ã®è§£æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚\n"

        # 2. ãƒ¬ã‚·ãƒ”åˆ¤å®š
        check_text = raw_text if not is_youtube else (title + " " + message_content)
        is_recipe = self._is_recipe(title, url, check_text)

        # 3. ä¿å­˜å…ˆãƒ•ã‚©ãƒ«ãƒ€ã¨ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®æ±ºå®š
        if is_recipe:
            folder_name = "Recipes"
            content_type_label = "Recipe"
        elif is_youtube:
            folder_name = "YouTube"
            content_type_label = "YouTube"
        else:
            folder_name = "WebClips"
            content_type_label = "WebClip"

        section_header = f"## {folder_name}"

        # 4. ãƒ•ã‚¡ã‚¤ãƒ«åã¨ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ä½œæˆ
        now = datetime.datetime.now(JST)
        timestamp = now.strftime('%Y%m%d%H%M%S')
        daily_note_date = now.strftime('%Y-%m-%d')
        
        safe_title = re.sub(r'[\\/*?:"<>|]', "", title)
        if not safe_title: safe_title = "Untitled"
        
        filename = f"{timestamp}-{safe_title}.md"
        filename_no_ext = f"{timestamp}-{safe_title}"
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ¡ãƒ¢ã‚’æŠ½å‡ºï¼ˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰URLã‚’å–ã‚Šé™¤ã„ãŸéƒ¨åˆ†ï¼‰
        user_comment = message_content.replace(url, "").strip()
        note_section = f"## Note\n{user_comment}\n\n" if user_comment else ""

        final_content = ""
        summary_text = ""
        
        if is_youtube:
            # YouTubeå½¢å¼
            final_content = (
                f"- **URL:** {url}\n"
                f"- **Channel:** {author_name}\n"
                f"- **Saved at:** {now}\n\n"
                f"{note_section}"
                f"---\n"
                f"[[{daily_note_date}]]"
            )
            summary_text = f"YouTubeå‹•ç”»ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {title}"
        else:
            # Webè¨˜äº‹ãƒ»ãƒ¬ã‚·ãƒ”å½¢å¼
            if len(raw_text) < 10:
                logging.warning(f"WebClip Warning: Content might be empty. URL: {url}")
                raw_text = "â€»æœ¬æ–‡ã®è‡ªå‹•å–å¾—ãŒã§ããªã‹ã£ãŸãƒšãƒ¼ã‚¸ã§ã™ã€‚\n"

            final_content = (
                f"- **Source:** <{url}>\n"
                f"- **Saved at:** {now}\n\n"
                f"{note_section}"
                f"---\n\n"
                f"[[{daily_note_date}]]\n\n"
                f"{raw_text}"
            )
            summary_text = f"Webè¨˜äº‹ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {title}"
            
        if is_recipe:
            summary_text = f"ãƒ¬ã‚·ãƒ”ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {title}"

        # 5. Driveã¸ä¿å­˜
        service = self.drive_service.get_service()
        if not service:
            await trigger_message_obj.add_reaction('âŒ')
            return None

        try:
            # ãƒ•ã‚©ãƒ«ãƒ€å–å¾—ãƒ»ä½œæˆ
            folder_id = await self.drive_service.find_file(service, self.drive_service.folder_id, folder_name)
            if not folder_id:
                folder_id = await self.drive_service.create_folder(service, self.drive_service.folder_id, folder_name)
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
            await self.drive_service.upload_text(service, folder_id, filename, final_content)

            # æ—¥è¨˜ã¸ãƒªãƒ³ã‚¯
            link_str = f"- [[{folder_name}/{filename_no_ext}|{title}]]"
            
            await self.drive_service.update_daily_note(service, daily_note_date, link_str, section_header)

            await trigger_message_obj.reply(f"âœ… {content_type_label}ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚\nğŸ“‚ `{folder_name}/{filename}`")
            
            return {
                "title": title,
                "summary": summary_text,
                "type": content_type_label
            }

        except Exception as e:
            logging.error(f"WebClip: Save Error: {e}")
            await trigger_message_obj.add_reaction('âŒ')
            return None